{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assign.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(), cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "stats.pointbiserialr(df[\"y\"], df[\"x9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='y',palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"x7\", y=\"x9\", hue=\"y\",data=df, palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='x1',y='x9',data=df,kind='scatter', hue='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='x10',y='x17',data=df,kind='scatter', hue='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.violinplot(x='x2',y='x13',data=df, hue='y', palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.violinplot(x='x2',y='x16',data=df, hue='y', palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.violinplot(x='x2',y='x17',data=df, hue='y', palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins = 50, figsize = (20, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['x15'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='x3', hue='x8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(data=df, x='x2', hue='x4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='x3', hue='x4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Now we need to process null value, but we need to identify what is the null value represent in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x4'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x5'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x6'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x7'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['x8'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can conclude that null value will include NaN and unknown for categorical data. Besides, there will have NaN value for x14 for numerical data. So we need to tell pandas to treat these values as null value. *Note - NaN is defaultly represent null value so we need to include this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_values = ['NaN', \"unknown\"]\n",
    "na_values = ['NaN', \"unknown\"]\n",
    "data = pd.read_csv(\"assign.csv\", na_values=na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph below, we know that the distribution of null value according to each column in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().plot(kind='bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we will handle the null value with following tehnique using folowing method\n",
    "- Filling in using median value for x14\n",
    "- Fill in mostly appear value for categorical data [x2, x3, x4, x5, x6, x8]\n",
    "- Drop x14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = data['x14'].median()\n",
    "data['x14'].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequently value for x3\n",
    "data.mode().loc[:,['x2', 'x3', 'x4', 'x5', 'x6', 'x8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill x3, x2, x8 with most frequently occuring value\n",
    "data['x2'].fillna(\"admin\", inplace=True)\n",
    "data['x3'].fillna(\"married\", inplace=True)\n",
    "data['x4'].fillna(\"university\", inplace=True)\n",
    "data['x5'].fillna(\"yes\", inplace=True)\n",
    "data['x6'].fillna(\"no\", inplace=True)\n",
    "data['x8'].fillna(\"cell\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"x11\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are only 3 percent of data that is not 999.\n",
    "# In other word, there are 97 percent of data value is 999\n",
    "# Therefore, this column doesn't have any value for modeling.\n",
    "data['x11'][data['x11'] != 999].count() / data['x11'][data['x11'] == 999].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"x11\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"x12\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 15 percent of data value is not 0\n",
    "# In other word, there are 85 percent of data value is 0\n",
    "# This column may have some value for modeling, however \n",
    "# we would drop it for fine tuning section to see whether the performance of model improve if we drop this column.\n",
    "data['x12'][data['x12'] != 0].count() / data['x12'][data['x12'] == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical data to numerical data using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train data to categorical and numerical\n",
    "X_train_num = X_train.drop(['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8'], axis=1)\n",
    "X_train_cat = X_train[['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessing instances\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After deal with categorical and numerical data, we need to resample the data since \n",
    "# it has unbalance data\n",
    "# So, false value is far greater than true value\n",
    "y.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "This resampling technique is temparory, more resampling technique will be examine in fine tune section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to resample the data to balance the data\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_prepared, y_train)\n",
    "\n",
    "ax = y_train_resampled.value_counts().plot.pie()\n",
    "ax.set_title(\"Random Undersampling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=5000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sgd_clf.predict(X_test_preapred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this result is from y_test with not yet resample.\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Unresempled test data prediction\") \n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the result from y_test after resample\n",
    "X_test_resampled, y_test_resampled = rus.fit_resample(X_test_preapred, y_test)\n",
    "sgd_clf_resampled = SGDClassifier(max_iter=5000, tol=1e-3, random_state=42)\n",
    "sgd_clf_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "predictions = sgd_clf.predict(X_test_resampled)\n",
    "print(\"Resempled test data prediction\") \n",
    "print(classification_report(y_test_resampled, predictions))\n",
    "print(confusion_matrix(y_test_resampled, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing cross validation\n",
    "# However the cross validation score seem not too good.\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "sgd_clf = SGDClassifier(max_iter=5000, tol=1e-3, random_state=42)\n",
    "pipeline = imbpipeline(steps = [['randomUnderSample', RandomUnderSampler(random_state=11)],\n",
    "                                ['scaler', StandardScaler()],\n",
    "                                ['classifier', sgd_clf]])\n",
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)\n",
    "params = {\n",
    "    \"classifier__loss\" : [\"hinge\", \"log_loss\", \"squared_hinge\", \"modified_huber\", \"perceptron\"],\n",
    "    \"classifier__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"classifier__penalty\" : [\"l2\", \"l1\", \"elasticnet\", \"none\"],\n",
    "}\n",
    "#     grid = GridSearchCV(clf, param_grid=params, cv=5)\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=params,\n",
    "                           scoring='f1',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test_preapred, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(f'Best parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 fine tuning and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to visualization above, we found that x10 and x13 is important feature that\n",
    "able to clear classify of true and false value.\n",
    "\n",
    "As mention in data preprocessing, we can fine tune the model by removing x12.\n",
    "\n",
    "Clearly that removing x12 and applying polynominal to features x10 and x13 will improve precision. For obvious result, the f1-score after fine tune is imporve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "# Fine tune the data before feed to model\n",
    "X_train_num_copy = X_train_num.copy()\n",
    "X_train_num_copy = X_train_num_copy.drop(\"x12\", axis=1)\n",
    "X_train_cat_copy = X_train_cat.copy()\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x5\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x6\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x7\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x8\", axis=1) # Fine tune\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        # polynomial transformation\n",
    "        (\"poly\", poly, X_train_num_copy[['x10', 'x13', 'x16']].columns), # Fine tune \n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = full_pipeline.transform(X_test)\n",
    "\n",
    "# Now we need to resample the data to balance the data\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_prepared, y_train)\n",
    "X_test_resampled, y_test_resampled = rus.fit_resample(X_test_preapred, y_test)\n",
    "\n",
    "# Train the model\n",
    "sgd_clf = SGDClassifier(max_iter=5000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on unresempled data\n",
    "predictions = sgd_clf.predict(X_test_preapred)\n",
    "print(\"Unresempled test data prediction\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))   \n",
    "\n",
    "# Test the model on resempled data\n",
    "predictions_resempled = sgd_clf.predict(X_test_resampled)  \n",
    "print(\"Resempled test data prediction\")  \n",
    "print(classification_report(y_test_resampled, predictions_resempled))\n",
    "print(confusion_matrix(y_test_resampled, predictions_resempled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross validation again from modified column transform\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "# Fine tune the data before feed to cross validation model\n",
    "X_train_num_copy = X_train_num.copy()\n",
    "X_train_num_copy = X_train_num_copy.drop(\"x12\", axis=1)\n",
    "X_train_cat_copy = X_train_cat.copy()\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x5\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x6\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x7\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x8\", axis=1) # Fine tune\n",
    "column_transformer_pipeline = ColumnTransformer([\n",
    "        # polynomial transformation\n",
    "        (\"poly\", poly, X_train_num_copy[['x10', 'x13', 'x16']].columns), # Fine tune \n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = column_transformer_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = column_transformer_pipeline.transform(X_test)\n",
    "\n",
    "pipeline = imbpipeline(steps = [['randomUnderSample', RandomUnderSampler(random_state=11)],\n",
    "                                ['classifier', sgd_clf]])\n",
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)\n",
    "params = {\n",
    "    \"classifier__loss\" : [\"hinge\", \"log_loss\", \"squared_hinge\", \"modified_huber\", \"perceptron\"],\n",
    "    \"classifier__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"classifier__penalty\" : [\"l2\", \"l1\", \"elasticnet\", \"none\"],\n",
    "}\n",
    "#     grid = GridSearchCV(clf, param_grid=params, cv=5)\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=params,\n",
    "                           scoring='f1',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test_preapred, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(f'Best parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attemmpt oversampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "# Fine tune the data before feed to model\n",
    "X_train_num_copy = X_train_num.copy()\n",
    "X_train_num_copy = X_train_num_copy.drop(\"x12\", axis=1)\n",
    "X_train_cat_copy = X_train_cat.copy()\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x5\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x6\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x7\", axis=1) # Fine tune\n",
    "X_train_cat_copy = X_train_cat_copy.drop(\"x8\", axis=1) # Fine tune\n",
    "full_pipeline = ColumnTransformer([\n",
    "        # polynomial transformation\n",
    "        (\"poly\", poly, X_train_num_copy[['x10', 'x13', 'x16']].columns), # Fine tune \n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = full_pipeline.transform(X_test)\n",
    "\n",
    "# Now we need to resample the data to balance the data\n",
    "smote = SMOTE(random_state=42, sampling_strategy=1)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_prepared, y_train)\n",
    "X_test_resampled, y_test_resampled = smote.fit_resample(X_test_preapred, y_test)\n",
    "\n",
    "# Train the model\n",
    "sgd_clf = SGDClassifier(max_iter=5000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on unresempled data\n",
    "predictions = sgd_clf.predict(X_test_preapred)\n",
    "print(\"Unresempled test data prediction\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))   \n",
    "\n",
    "# Test the model on resempled data\n",
    "predictions_resempled = sgd_clf.predict(X_test_resampled)  \n",
    "print(\"Resempled test data prediction\")  \n",
    "print(classification_report(y_test_resampled, predictions_resempled))\n",
    "print(confusion_matrix(y_test_resampled, predictions_resempled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imbpipeline(steps = [['SMOTE', SMOTE(random_state=11)],\n",
    "                                ['classifier', sgd_clf]])\n",
    "stratified_kfold = StratifiedKFold(n_splits=3,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=11)\n",
    "params = {\n",
    "    \"classifier__loss\" : [\"hinge\", \"log_loss\", \"squared_hinge\", \"modified_huber\", \"perceptron\"],\n",
    "    \"classifier__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"classifier__penalty\" : [\"l2\", \"l1\", \"elasticnet\", \"none\"],\n",
    "}\n",
    "#     grid = GridSearchCV(clf, param_grid=params, cv=5)\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=params,\n",
    "                           scoring='f1',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X_train_prepared, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test_resampled, y_test_resampled)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(f'Best parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDclassifier_beforefinetune is classifier before fine tune (column selection and modification)\n",
    "# SGDclassifier_v1 is undersample version of best parameter of SGDclassifier\n",
    "# SGDclassifier_v2 is oversample version of best parameter of SGDclassifier\n",
    "# Oversampling is better than undersampling in this case, that cover most of the data\n",
    "from sklearn.metrics import DetCurveDisplay, RocCurveDisplay\n",
    "classifiers = {\n",
    "    \"SGDClassifier_beforefinetune\": SGDClassifier(max_iter=5000, tol=1e-3, random_state=42, alpha=0.01, loss=\"log_loss\", penalty=\"none\"),\n",
    "    \"SGDclassifier_v1\":  SGDClassifier(max_iter=5000, tol=1e-3, random_state=42, alpha=0.001, loss=\"hinge\", penalty=\"l2\"),\n",
    "    \"SGDclassifier_v2\": SGDClassifier(max_iter=5000, tol=1e-3, random_state=42, alpha=0.01, loss=\"modified_huber\", penalty=\"elasticnet\"),\n",
    "}\n",
    "fig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_prepared, y_train)\n",
    "\n",
    "    RocCurveDisplay.from_estimator(clf, X_test_preapred, y_test, ax=ax_roc, name=name)\n",
    "    DetCurveDisplay.from_estimator(clf, X_test_preapred, y_test, ax=ax_det, name=name)\n",
    "ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n",
    "ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n",
    "\n",
    "ax_roc.grid(linestyle=\"--\")\n",
    "ax_det.grid(linestyle=\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstanciate data for model 2\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train data to categorical and numerical\n",
    "X_train_num = X_train.drop(['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8'], axis=1)\n",
    "X_train_cat = X_train[['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8']]\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = full_pipeline.transform(X_test)\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter = 5000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_preapred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Fine Tune and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gridsearchcv to find best hyperparameter for the model\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "penalty = ['l2', 'none']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use oversampling technique and fine tune the model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_prepared, y_train)\n",
    "\n",
    "logreg = LogisticRegression(C=10, solver='newton-cg', penalty='l2', max_iter=5000)\n",
    "logreg.fit(X_res, y_res)\n",
    "y_pred = logreg.predict(X_test_preapred)     \n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - KNeighboursClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstanciate data for model 3\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train data to categorical and numerical\n",
    "X_train_num = X_train.drop(['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8'], axis=1)\n",
    "X_train_cat = X_train[['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8']]\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = full_pipeline.transform(X_test)\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test_preapred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 Fine Tuning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "enn  = EditedNearestNeighbours()\n",
    "X_train_resampled, y_train_resampled = enn.fit_resample(X_train_prepared, y_train)\n",
    "\n",
    "ax = y_train_resampled.value_counts().plot.pie()\n",
    "ax.set_title(\"undersampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh2 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh2.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred2 = neigh2.predict(X_test_preapred)\n",
    "\n",
    "print(\"Before fine-tuning:\")\n",
    "# Model 3 performance (before fine-tuning + before resampling):\n",
    "print(\"Performance before resampling:\")\n",
    "print(classification_report(y_test, y_pred))    # classification_report(real, predicted)\n",
    "\n",
    "# Model 3 performance (before fine-tuning + after resampling):\n",
    "print(\"Performance after resampling:\")\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning: Finding the best hyperparameter for the model (with data before resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameters to tune:\n",
    "leaf_size = list(range(1,15))\n",
    "n_neighbors = list(range(1,6))\n",
    "p=[1,2]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "neigh2 = KNeighborsClassifier()\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(neigh2, hyperparameters, cv=10)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train_prepared, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning: Finding the best hyperparameter for the model (with data after resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune:\n",
    "leaf_size = list(range(1,15))\n",
    "n_neighbors = list(range(1,6))\n",
    "p=[1,2]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "neigh2 = KNeighborsClassifier()\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(neigh2, hyperparameters, cv=10)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the performance of Model 3 (after fine-tuning) by using the best hyperparameter found:<br>\n",
    "A. Using best hyperparameter found with data before resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with best hyperparameter 1 (before resampling)\n",
    "best_neigh1_bef_res = KNeighborsClassifier(n_neighbors=5, p=2, leaf_size=1)\n",
    "best_neigh1_bef_res.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Model with best hyperparameter 1 (after resampling)\n",
    "best_neigh1_res = KNeighborsClassifier(n_neighbors=5, p=2, leaf_size=1)\n",
    "best_neigh1_res.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test both model with prepared test data\n",
    "best_neigh1_bef_res_pred = best_neigh1_bef_res.predict(X_test_preapred)\n",
    "best_neigh1_res_pred = best_neigh1_res.predict(X_test_preapred)\n",
    "\n",
    "print(\"After fine-tuning:\")\n",
    "# Model 3 performance (after fine-tuning + before resampling):\n",
    "print(\"Performance before resampling:\")\n",
    "print(classification_report(y_test, best_neigh1_bef_res_pred))\n",
    "\n",
    "# Model 3 performance (after fine-tuning + after resampling):\n",
    "print(\"Performance after resampling:\")\n",
    "print(classification_report(y_test, best_neigh1_res_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Using best hyperparameter found with data after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with best hyperparameter 2 (before resampling)\n",
    "best_neigh2_bef_res = KNeighborsClassifier(n_neighbors=1, p=2, leaf_size=1)\n",
    "best_neigh2_bef_res.fit(X_train_prepared, y_train)\n",
    "\n",
    "# Model with best hyperparameter 2 (after resampling)\n",
    "best_neigh2_res = KNeighborsClassifier(n_neighbors=1, p=2, leaf_size=1)\n",
    "best_neigh2_res.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test both model with prepared test data\n",
    "best_neigh2_bef_res_pred = best_neigh2_bef_res.predict(X_test_preapred)\n",
    "best_neigh2_res_pred = best_neigh2_res.predict(X_test_preapred)\n",
    "\n",
    "print(\"After fine-tuning:\")\n",
    "# Model 3 performance (after fine-tuning + before resampling):\n",
    "print(\"Performance before resampling:\")\n",
    "print(classification_report(y_test, best_neigh2_bef_res_pred))\n",
    "\n",
    "# Model 3 performance (after fine-tuning + after resampling):\n",
    "print(\"Performance after resampling:\")\n",
    "print(classification_report(y_test, best_neigh2_res_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roc_auc_score with default and best hyperparemeter 1 & 2, both with original & resampled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Before fine-tuning:\")\n",
    "print('roc_aoc_score before resampling =', roc_auc_score(y_test, y_pred))\n",
    "print('roc_aoc_score after resampling =', roc_auc_score(y_test, y_pred2))\n",
    "print('Difference =', roc_auc_score(y_test, y_pred2) - roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"After fine-tuning with hyperparameters found using non-resampled data:\")\n",
    "print('roc_aoc_score before resampling (fine-tuned) =', roc_auc_score(y_test, best_neigh1_bef_res_pred))\n",
    "print('roc_aoc_score after resampling (fine-tuned) =', roc_auc_score(y_test, best_neigh1_res_pred))\n",
    "print('Difference =', roc_auc_score(y_test, best_neigh1_res_pred) - roc_auc_score(y_test, best_neigh1_bef_res_pred))\n",
    "\n",
    "print('')\n",
    "print(\"After fine-tuning with hyperparameters found using resampled (undersampled) data:\")\n",
    "print('roc_aoc_score before resampling (fine-tuned) =', roc_auc_score(y_test, best_neigh2_bef_res_pred))\n",
    "print('roc_aoc_score after resampling (fine-tuned) =', roc_auc_score(y_test, best_neigh2_res_pred))\n",
    "print('Difference =', roc_auc_score(y_test, best_neigh2_res_pred) - roc_auc_score(y_test, best_neigh2_bef_res_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**\n",
    "1. Before fine-tuning the model:<br>\n",
    "    (a) The roc_aoc_score using non-resampled data is higher than 2(a) but lower than 3(a).<br>\n",
    "    (b) The roc_aoc_score using resampled data is higher than 3(b) but lower than 2(b).<br>\n",
    "    (c) The improvement of roc_aoc_score is slightly higher than the improvement of roc_aoc_score of 3(c).<br>\n",
    "    <br>\n",
    "2. After fine-tuning the model with hyperparameters found using non-resampled data:<br>\n",
    "    (a) The roc_aoc_score using non-resampled data is the lowest.<br>\n",
    "    (b) The roc_aoc_score using resampled data is the highest.<br>\n",
    "    (c) The improvement of roc_aoc_score is the most.<br>\n",
    "    <br>\n",
    "3. After fine-tuning the model with hyperparameters found using resampled (undersampled) data:<br>\n",
    "    (a) The roc_aoc_score using non-resampled data is the highest.<br>\n",
    "    (b) The roc_aoc_score using resampled data is the lowest.<br>\n",
    "    (c) The improvement of roc_aoc_score is the least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance Comparision between Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstanciate data for model 3\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split train data to categorical and numerical\n",
    "X_train_num = X_train.drop(['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8'], axis=1)\n",
    "X_train_cat = X_train[['x2', 'x3', 'x4', 'x5', 'x6', 'x7' ,'x8']]\n",
    "scalar = StandardScaler()\n",
    "encode = OneHotEncoder()\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"scaler\", scalar, X_train_num.columns),\n",
    "        (\"encode\", encode, X_train_cat.columns),\n",
    "    ])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_test_preapred = full_pipeline.transform(X_test)\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDclassifier_beforefinetune is classifier before fine tune (column selection and modification)\n",
    "# SGDclassifier_v1 is undersample version of best parameter of SGDclassifier\n",
    "# SGDclassifier_v2 is oversample version of best parameter of SGDclassifier\n",
    "# Oversampling is better than undersampling in this case, that cover most of the data\n",
    "from sklearn.metrics import DetCurveDisplay, RocCurveDisplay\n",
    "classifiers = {\n",
    "    \"SGDclassifier\": SGDClassifier(max_iter=5000, tol=1e-3, random_state=42, alpha=0.01, loss=\"modified_huber\", penalty=\"elasticnet\"),\n",
    "    \"LogisticRegression\": LogisticRegression(C=10, solver='newton-cg', penalty='l2', max_iter=5000),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(n_neighbors=1, p=2, leaf_size=1),\n",
    "}\n",
    "fig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_prepared, y_train)\n",
    "\n",
    "    RocCurveDisplay.from_estimator(clf, X_test_preapred, y_test, ax=ax_roc, name=name)\n",
    "    DetCurveDisplay.from_estimator(clf, X_test_preapred, y_test, ax=ax_det, name=name)\n",
    "ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n",
    "ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n",
    "\n",
    "ax_roc.grid(linestyle=\"--\")\n",
    "ax_det.grid(linestyle=\"--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50cdb416bb757b9dfcaaba302023faa8d9a442df233820f0ddfde94ba89bc06c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
